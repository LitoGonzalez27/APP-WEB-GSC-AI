# üîß Soluci√≥n: Queries Incompletas en LLM Monitoring

**Fecha**: 06 de Noviembre de 2025  
**Estado**: ‚úÖ RESUELTO

---

## üìã Problema Reportado

El usuario report√≥ que en la secci√≥n "LLM Comparison":

1. **Claude mostraba 4.5% mention rate pero dec√≠a "0 de 22 queries"** (deber√≠a ser 0%)
2. **Diferentes LLMs ten√≠an diferentes cantidades de queries**:
   - Gemini: 15 queries
   - ChatGPT: 6 queries  
   - Perplexity: 22 queries
   - Claude: 22 queries

**Expectativa del usuario**: Todos los LLMs deber√≠an analizar TODAS las queries.

---

## üîç Diagn√≥stico Realizado

Ejecutamos el script `diagnose_llm_queries.py` para el proyecto #5 (HM Fertility):

```bash
python3 diagnose_llm_queries.py 5
```

### Resultados del Diagn√≥stico (06-11-2025):

**Total de queries activas**: 22

**Queries analizadas por LLM**:
| LLM | Queries Analizadas | Estado | Completitud |
|-----|-------------------|--------|-------------|
| **Claude** | 22/22 | ‚úÖ | 100% |
| **Gemini** | 18/22 | ‚ö†Ô∏è | 81.8% |
| **ChatGPT** | 13/22 | ‚ö†Ô∏è | 59.1% |
| **Perplexity** | 22/22 | ‚úÖ | 100% |

**Snapshots del 06-11-2025**:
| LLM | Queries en Snapshot | Menciones | Mention Rate |
|-----|---------------------|-----------|--------------|
| Claude | 22 | 1 | 4.6% ‚úÖ |
| Gemini | 15 | 1 | 6.7% (parcial) |
| ChatGPT | 6 | 1 | 16.7% (parcial) |
| Perplexity | 22 | 11 | 50.0% ‚úÖ |

### üéØ Causa Ra√≠z Identificada:

1. **Queries faltantes por API failures**: Algunas queries fallaban en ciertos LLMs (rate limits, timeouts)
2. **Snapshots con datos parciales**: Los snapshots se creaban con las queries que S√ç se analizaron, sin validar completitud
3. **Falta de visibilidad**: No hab√≠a advertencias sobre an√°lisis incompletos
4. **Porcentajes enga√±osos**: Un snapshot de 6 queries mostraba 16.7% cuando deber√≠a calcularse sobre 22

---

## ‚úÖ Soluci√≥n Implementada

### 1. **Validaci√≥n de Completitud** 

El sistema ahora verifica que cada LLM analice TODAS las queries:

```python
total_queries_expected = len(queries)  # Ej: 22

for llm_name, llm_results in results_by_llm.items():
    queries_analyzed = len(llm_results)
    
    if queries_analyzed < total_queries_expected:
        # ‚ö†Ô∏è ADVERTENCIA clara en logs
        missing = total_queries_expected - queries_analyzed
        logger.warning(f"‚ö†Ô∏è  AN√ÅLISIS INCOMPLETO PARA {llm_name}")
        logger.warning(f"   Queries faltantes: {missing}")
        logger.warning(f"   Completitud: {queries_analyzed/total_queries_expected*100:.1f}%")
```

### 2. **Logging Mejorado**

Ahora ver√°s advertencias claras cuando un an√°lisis no es completo:

```
‚ö†Ô∏è  AN√ÅLISIS INCOMPLETO PARA OPENAI
   Queries esperadas: 22
   Queries analizadas: 13
   Queries faltantes: 9
   Completitud: 59.1%

   ‚ö†Ô∏è  El snapshot se crear√° con DATOS PARCIALES
   ‚ö†Ô∏è  Los porcentajes pueden no ser representativos
   ‚ö†Ô∏è  Considera ejecutar un nuevo an√°lisis
```

### 3. **Script de Diagn√≥stico**

Nuevo script `diagnose_llm_queries.py` que te permite:

```bash
# Diagnosticar un proyecto
python3 diagnose_llm_queries.py <project_id>

# Ejemplo
python3 diagnose_llm_queries.py 5
```

**El script muestra:**
- ‚úÖ Queries totales del proyecto
- ‚úÖ Queries analizadas por cada LLM
- ‚úÖ Queries faltantes espec√≠ficas
- ‚úÖ Validaci√≥n de snapshots
- ‚úÖ Recomendaciones

### 4. **Resultado de An√°lisis Mejorado**

El endpoint de an√°lisis ahora devuelve:

```json
{
  "project_id": 5,
  "analysis_date": "2025-11-06",
  "completeness_by_llm": {
    "openai": {
      "queries_analyzed": 13,
      "queries_expected": 22,
      "completeness_pct": 59.1
    },
    "google": {
      "queries_analyzed": 18,
      "queries_expected": 22,
      "completeness_pct": 81.8
    },
    ...
  },
  "incomplete_llms": ["openai", "google"],
  "all_queries_analyzed": false  // ‚ö†Ô∏è An√°lisis incompleto
}
```

---

## üöÄ Recomendaciones

### Acci√≥n Inmediata:

1. **Ejecutar un nuevo an√°lisis completo** desde el dashboard:
   - Ve a LLM Monitoring
   - Selecciona tu proyecto
   - Haz clic en "Run Analysis"
   - Espera a que termine (puede tardar varios minutos)

2. **Revisar los logs del an√°lisis**:
   - Ver√°s claramente si alg√∫n LLM no complet√≥ todas las queries
   - Ver√°s qu√© queries espec√≠ficas fallaron
   - Ver√°s el porcentaje de completitud

3. **Si sigue habiendo queries faltantes**:
   - Revisa los logs para identificar el error espec√≠fico
   - Posibles causas:
     - **Rate limits**: Demasiadas peticiones por minuto
     - **Timeouts**: Queries muy largas que tardan demasiado
     - **API errors**: Problemas temporales con la API del LLM

### Acciones a Largo Plazo:

1. **Monitorear completitud**: Despu√©s de cada an√°lisis, revisa si `all_queries_analyzed = true`

2. **Ajustar rate limits** si es necesario:
   - Reduce `max_workers` en el an√°lisis (actualmente 10)
   - A√±ade delays entre peticiones si ciertos LLMs dan rate limits

3. **Reintentar queries fallidas**:
   - Considera implementar un sistema de retry autom√°tico para queries fallidas

---

## üìä Ejemplo de Uso del Script de Diagn√≥stico

```bash
$ python3 diagnose_llm_queries.py 5

================================================================================
üîç DIAGN√ìSTICO DE PROYECTO #5
================================================================================

üìã 1. INFORMACI√ìN DEL PROYECTO
--------------------------------------------------------------------------------
Nombre: HM Fertility
Marca: hm fertility
LLMs habilitados: openai, anthropic, google, perplexity
Queries por LLM configuradas: 20
√öltimo an√°lisis: 2025-11-06 13:19:16

üìä 2. QUERIES/PROMPTS DEL PROYECTO
--------------------------------------------------------------------------------
Total de queries activas: 22

ü§ñ 3. RESULTADOS POR LLM (√∫ltimos 7 d√≠as)
--------------------------------------------------------------------------------

LLM             Queries    Menciones    Errores    √öltimo An√°lisis
--------------------------------------------------------------------------------
‚úÖ anthropic     22         4            0          2025-11-06
‚ö†Ô∏è  google        18         4            0          2025-11-06
‚ö†Ô∏è  openai        13         3            0          2025-11-06
‚úÖ perplexity    22         33           0          2025-11-06

üí° 7. RECOMENDACIONES
--------------------------------------------------------------------------------

‚ö†Ô∏è  Algunos LLMs no han analizado todas las queries:
   Posibles causas:
   1. Errores en las llamadas a la API (rate limits, timeouts)
   2. Health check excluyendo providers
   3. Queries a√±adidas despu√©s del √∫ltimo an√°lisis

   Soluci√≥n:
   ‚Üí Ejecutar un nuevo an√°lisis desde el dashboard
   ‚Üí Verificar logs del an√°lisis para ver errores
```

---

## üéØ Resumen de Cambios en el C√≥digo

### Archivos Modificados:

1. **`services/llm_monitoring_service.py`**:
   - A√±adida validaci√≥n de completitud antes de crear snapshots
   - Logging de advertencia para an√°lisis incompletos
   - Info de completitud en logs de snapshot
   - Resultado mejorado con datos de completitud

2. **`diagnose_llm_queries.py`** (NUEVO):
   - Script completo de diagn√≥stico
   - Identifica queries faltantes
   - Valida consistencia de snapshots
   - Genera recomendaciones

### Commit:

```
commit: 12717ee
branch: staging
message: "fix: Validar y reportar queries faltantes en an√°lisis LLM"
```

---

## ‚úÖ Verificaci√≥n

Para verificar que la soluci√≥n funciona:

1. **Ejecuta un an√°lisis nuevo**:
   ```bash
   # Desde el dashboard o por API:
   POST /api/llm-monitoring/projects/5/analyze
   ```

2. **Revisa los logs** en Railway:
   ```bash
   railway logs --filter "LLM Monitoring"
   ```

3. **Ejecuta el diagn√≥stico**:
   ```bash
   python3 diagnose_llm_queries.py 5
   ```

4. **Verifica que todos los LLMs muestren**:
   - ‚úÖ Queries esperadas = Queries analizadas
   - ‚úÖ Completitud: 100%

---

## üîÆ Mejoras Futuras Posibles

1. **Sistema de retry autom√°tico**: Reintentar queries fallidas autom√°ticamente
2. **Alerta en dashboard**: Mostrar badge de "An√°lisis Incompleto" en la UI
3. **Rate limit inteligente**: Ajustar velocidad seg√∫n respuesta del LLM
4. **An√°lisis parcial diferido**: Guardar queries fallidas y reintentarlas m√°s tarde

---

## üìû Soporte

**Script de diagn√≥stico**:
```bash
python3 diagnose_llm_queries.py <project_id>
```

**Revisar logs en Railway**:
```bash
railway logs --service=web
```

**Estado actual**: ‚úÖ Sistema operativo con validaciones implementadas

