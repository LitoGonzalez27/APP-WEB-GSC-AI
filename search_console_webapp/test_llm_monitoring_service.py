#!/usr/bin/env python3
"""
Script de Test para Multi-LLM Monitoring Service

IMPORTANTE: Estos tests NO consumen API calls reales (excepto si se habilita)
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_imports():
    """Test 1: Verificar imports"""
    logger.info("")
    logger.info("=" * 70)
    logger.info("TEST 1: VERIFICANDO IMPORTS")
    logger.info("=" * 70)
    
    try:
        from services.llm_monitoring_service import (
            MultiLLMMonitoringService,
            analyze_all_active_projects
        )
        logger.info("‚úÖ Imports exitosos")
        logger.info(f"   ‚Ä¢ MultiLLMMonitoringService: {MultiLLMMonitoringService}")
        logger.info(f"   ‚Ä¢ analyze_all_active_projects: {analyze_all_active_projects}")
        return True
    except Exception as e:
        logger.error(f"‚ùå Error en imports: {e}", exc_info=True)
        return False


def test_query_generation():
    """Test 2: Generaci√≥n de queries"""
    logger.info("")
    logger.info("=" * 70)
    logger.info("TEST 2: GENERACI√ìN DE QUERIES")
    logger.info("=" * 70)
    
    try:
        from services.llm_monitoring_service import MultiLLMMonitoringService
        
        # Crear servicio (sin API keys reales, solo para tests)
        # En producci√≥n, usar API keys reales
        api_keys = {
            'google': 'test-key-for-structure'  # No se usar√° para queries
        }
        
        # No validar conexi√≥n en tests
        from services.llm_providers import LLMProviderFactory
        LLMProviderFactory.create_provider = lambda *args, **kwargs: None  # Mock
        
        try:
            service = MultiLLMMonitoringService.__new__(MultiLLMMonitoringService)
            service.providers = {}
            service.sentiment_analyzer = None
            
            # Test generaci√≥n de queries en espa√±ol
            queries_es = service.generate_queries_for_project(
                brand_name="Quipu",
                industry="software de facturaci√≥n",
                language="es",
                competitors=["Holded", "Sage"],
                count=15
            )
            
            logger.info(f"Queries generadas (ES): {len(queries_es)}")
            
            if len(queries_es) != 15:
                logger.error(f"   ‚ùå Esperadas 15 queries, obtenidas {len(queries_es)}")
                return False
            
            # Verificar estructura
            for query in queries_es[:3]:
                logger.info(f"   ‚Ä¢ {query['query_text'][:60]}... ({query['query_type']})")
                
                if 'query_text' not in query or 'language' not in query or 'query_type' not in query:
                    logger.error("   ‚ùå Estructura de query incorrecta")
                    return False
            
            # Test generaci√≥n en ingl√©s
            queries_en = service.generate_queries_for_project(
                brand_name="Quipu",
                industry="invoicing software",
                language="en",
                competitors=["Holded"],
                count=10
            )
            
            logger.info(f"Queries generadas (EN): {len(queries_en)}")
            
            if len(queries_en) != 10:
                logger.error(f"   ‚ùå Esperadas 10 queries, obtenidas {len(queries_en)}")
                return False
            
            logger.info("‚úÖ Generaci√≥n de queries funciona correctamente")
            return True
            
        except Exception as e:
            # Si falla por falta de proveedores, est√° OK (es esperado en test)
            if "No hay proveedores LLM disponibles" in str(e):
                logger.info("‚ö†Ô∏è No se pueden crear proveedores (esperado en test)")
                logger.info("   Saltando a test directo de m√©todos...")
                
                # Test directo del m√©todo
                service = MultiLLMMonitoringService.__new__(MultiLLMMonitoringService)
                service.providers = {}
                service.sentiment_analyzer = None
                
                queries = service.generate_queries_for_project(
                    brand_name="Test",
                    industry="test industry",
                    language="es",
                    count=5
                )
                
                if len(queries) == 5:
                    logger.info("‚úÖ M√©todo generate_queries_for_project funciona")
                    return True
                else:
                    logger.error(f"‚ùå Esperadas 5 queries, obtenidas {len(queries)}")
                    return False
            else:
                raise
        
    except Exception as e:
        logger.error(f"‚ùå Error en generaci√≥n de queries: {e}", exc_info=True)
        return False


def test_brand_mention_analysis():
    """Test 3: An√°lisis de menciones de marca"""
    logger.info("")
    logger.info("=" * 70)
    logger.info("TEST 3: AN√ÅLISIS DE MENCIONES DE MARCA")
    logger.info("=" * 70)
    
    try:
        from services.llm_monitoring_service import MultiLLMMonitoringService
        
        service = MultiLLMMonitoringService.__new__(MultiLLMMonitoringService)
        service.providers = {}
        service.sentiment_analyzer = None
        
        # Test 3.1: Menci√≥n clara
        logger.info("Test 3.1: Menci√≥n clara de marca...")
        
        response_1 = """
        Las mejores herramientas de facturaci√≥n son:
        1. Quipu - Excelente para aut√≥nomos
        2. Holded - Muy completa
        3. Sage - Para empresas grandes
        
        Quipu destaca por su facilidad de uso y precio competitivo.
        """
        
        result_1 = service.analyze_brand_mention(
            response_text=response_1,
            brand_name="Quipu",
            competitors=["Holded", "Sage"]
        )
        
        if not result_1['brand_mentioned']:
            logger.error("   ‚ùå No detect√≥ menci√≥n de Quipu")
            return False
        
        if result_1['mention_count'] < 2:
            logger.error(f"   ‚ùå Deber√≠a detectar 2+ menciones, detect√≥ {result_1['mention_count']}")
            return False
        
        if not result_1['appears_in_numbered_list']:
            logger.error("   ‚ùå No detect√≥ que aparece en lista numerada")
            return False
        
        if result_1['position_in_list'] != 1:
            logger.error(f"   ‚ùå Posici√≥n incorrecta: {result_1['position_in_list']}, esperada: 1")
            return False
        
        logger.info(f"   ‚úÖ Menci√≥n detectada correctamente")
        logger.info(f"      ‚Ä¢ Menciones: {result_1['mention_count']}")
        logger.info(f"      ‚Ä¢ Posici√≥n: {result_1['position_in_list']}")
        logger.info(f"      ‚Ä¢ Competidores: {result_1['competitors_mentioned']}")
        
        # Test 3.2: Sin menci√≥n
        logger.info("")
        logger.info("Test 3.2: Sin menci√≥n de marca...")
        
        response_2 = """
        Para facturaci√≥n recomiendo usar Holded o Sage.
        Son las mejores opciones del mercado.
        """
        
        result_2 = service.analyze_brand_mention(
            response_text=response_2,
            brand_name="Quipu",
            competitors=["Holded", "Sage"]
        )
        
        if result_2['brand_mentioned']:
            logger.error("   ‚ùå Detect√≥ menci√≥n cuando no la hay")
            return False
        
        if len(result_2['competitors_mentioned']) == 0:
            logger.error("   ‚ùå No detect√≥ competidores")
            return False
        
        logger.info(f"   ‚úÖ No-menci√≥n detectada correctamente")
        logger.info(f"      ‚Ä¢ Competidores mencionados: {list(result_2['competitors_mentioned'].keys())}")
        
        # Test 3.3: Variaciones de marca
        logger.info("")
        logger.info("Test 3.3: Variaciones de marca (GetQuipu, get quipu)...")
        
        response_3 = "GetQuipu es excelente. Tambi√©n puedes probar get quipu."
        
        result_3 = service.analyze_brand_mention(
            response_text=response_3,
            brand_name="Quipu",
            competitors=[]
        )
        
        if not result_3['brand_mentioned']:
            logger.error("   ‚ùå No detect√≥ variaciones de marca")
            return False
        
        logger.info(f"   ‚úÖ Variaciones detectadas correctamente")
        logger.info(f"      ‚Ä¢ Menciones: {result_3['mention_count']}")
        
        logger.info("")
        logger.info("‚úÖ An√°lisis de menciones funciona correctamente")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error en an√°lisis de menciones: {e}", exc_info=True)
        return False


def test_list_detection():
    """Test 4: Detecci√≥n de listas numeradas"""
    logger.info("")
    logger.info("=" * 70)
    logger.info("TEST 4: DETECCI√ìN DE LISTAS NUMERADAS")
    logger.info("=" * 70)
    
    try:
        from services.llm_monitoring_service import MultiLLMMonitoringService
        
        service = MultiLLMMonitoringService.__new__(MultiLLMMonitoringService)
        
        # Diferentes formatos de listas
        test_cases = [
            {
                'name': 'Lista con punto',
                'text': '1. Quipu\n2. Holded\n3. Sage',
                'expected_position': 1,
                'expected_total': 3
            },
            {
                'name': 'Lista con par√©ntesis',
                'text': '1) Holded\n2) Quipu\n3) Sage',
                'expected_position': 2,
                'expected_total': 3
            },
            {
                'name': 'Lista con markdown bold',
                'text': '**1.** Other\n**2.** Quipu\n**3.** Another',
                'expected_position': 2,
                'expected_total': 3
            }
        ]
        
        all_passed = True
        
        for test in test_cases:
            result = service.analyze_brand_mention(
                response_text=test['text'],
                brand_name="Quipu",
                competitors=[]
            )
            
            if not result['appears_in_numbered_list']:
                logger.error(f"   ‚ùå {test['name']}: No detect√≥ lista")
                all_passed = False
                continue
            
            if result['position_in_list'] != test['expected_position']:
                logger.error(f"   ‚ùå {test['name']}: Posici√≥n incorrecta")
                logger.error(f"      Esperada: {test['expected_position']}, Obtenida: {result['position_in_list']}")
                all_passed = False
                continue
            
            logger.info(f"   ‚úÖ {test['name']}: Posici√≥n {result['position_in_list']}/{result['total_items_in_list']}")
        
        if all_passed:
            logger.info("")
            logger.info("‚úÖ Detecci√≥n de listas funciona correctamente")
            return True
        else:
            return False
        
    except Exception as e:
        logger.error(f"‚ùå Error en detecci√≥n de listas: {e}", exc_info=True)
        return False


def test_sentiment_fallback():
    """Test 5: An√°lisis de sentimiento (fallback por keywords)"""
    logger.info("")
    logger.info("=" * 70)
    logger.info("TEST 5: AN√ÅLISIS DE SENTIMIENTO (FALLBACK)")
    logger.info("=" * 70)
    
    try:
        from services.llm_monitoring_service import MultiLLMMonitoringService
        
        service = MultiLLMMonitoringService.__new__(MultiLLMMonitoringService)
        service.sentiment_analyzer = None  # Forzar fallback
        
        test_cases = [
            {
                'contexts': ["Quipu es excelente y muy recomendado"],
                'expected_sentiment': 'positive',
                'name': 'Positivo'
            },
            {
                'contexts': ["Quipu es terrible y no lo recomiendo"],
                'expected_sentiment': 'negative',
                'name': 'Negativo'
            },
            {
                'contexts': ["Quipu es una herramienta de facturaci√≥n"],
                'expected_sentiment': 'neutral',
                'name': 'Neutral'
            }
        ]
        
        all_passed = True
        
        for test in test_cases:
            result = service._analyze_sentiment_keywords(test['contexts'])
            
            if result['sentiment'] != test['expected_sentiment']:
                logger.warning(f"   ‚ö†Ô∏è {test['name']}: Esperado {test['expected_sentiment']}, obtenido {result['sentiment']}")
                # No falla el test porque keywords es aproximado
            else:
                logger.info(f"   ‚úÖ {test['name']}: {result['sentiment']} (score: {result['score']:.2f})")
        
        logger.info("")
        logger.info("‚úÖ Sentimiento fallback funciona (m√©todo: keywords)")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error en sentimiento: {e}", exc_info=True)
        return False


def test_structure():
    """Test 6: Verificar estructura del servicio"""
    logger.info("")
    logger.info("=" * 70)
    logger.info("TEST 6: VERIFICANDO ESTRUCTURA DEL SERVICIO")
    logger.info("=" * 70)
    
    try:
        from services.llm_monitoring_service import MultiLLMMonitoringService
        
        required_methods = [
            'generate_queries_for_project',
            'analyze_brand_mention',
            '_analyze_sentiment_with_llm',
            '_analyze_sentiment_keywords',
            '_detect_position_in_list',
            'analyze_project',
            '_execute_single_query_task',
            '_create_snapshot'
        ]
        
        all_ok = True
        
        for method in required_methods:
            if hasattr(MultiLLMMonitoringService, method):
                logger.info(f"   ‚úÖ {method}")
            else:
                logger.error(f"   ‚ùå {method} - NO ENCONTRADO")
                all_ok = False
        
        if all_ok:
            logger.info("")
            logger.info("‚úÖ Todos los m√©todos requeridos est√°n implementados")
            return True
        else:
            return False
        
    except Exception as e:
        logger.error(f"‚ùå Error verificando estructura: {e}", exc_info=True)
        return False


def main():
    """Ejecutar todos los tests"""
    logger.info("")
    logger.info("‚ïî" + "‚ïê" * 68 + "‚ïó")
    logger.info("‚ïë" + " " * 10 + "TEST SUITE: MULTI-LLM MONITORING SERVICE" + " " * 18 + "‚ïë")
    logger.info("‚ïö" + "‚ïê" * 68 + "‚ïù")
    logger.info("")
    
    tests = [
        ("Imports", test_imports),
        ("Generaci√≥n de queries", test_query_generation),
        ("An√°lisis de menciones", test_brand_mention_analysis),
        ("Detecci√≥n de listas", test_list_detection),
        ("Sentimiento fallback", test_sentiment_fallback),
        ("Estructura del servicio", test_structure),
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            results[test_name] = result
        except Exception as e:
            logger.error(f"‚ùå Test '{test_name}' fall√≥ con excepci√≥n: {e}")
            results[test_name] = False
    
    # Resumen
    logger.info("")
    logger.info("=" * 70)
    logger.info("RESUMEN DE TESTS")
    logger.info("=" * 70)
    
    passed = sum(1 for r in results.values() if r)
    total = len(results)
    
    for test_name, result in results.items():
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        logger.info(f"{status}: {test_name}")
    
    logger.info("")
    logger.info("=" * 70)
    logger.info(f"RESULTADO FINAL: {passed}/{total} tests pasados")
    logger.info("=" * 70)
    logger.info("")
    
    if passed == total:
        logger.info("üéâ TODOS LOS TESTS PASARON")
        logger.info("")
        logger.info("‚úÖ Servicio Multi-LLM est√° correctamente implementado")
        logger.info("")
        logger.info("üéØ SIGUIENTE PASO:")
        logger.info("   1. Probar con API keys reales (opcional)")
        logger.info("   2. Crear proyecto de prueba en BD")
        logger.info("   3. Ejecutar analyze_project() con max_workers=10")
        logger.info("")
        return 0
    else:
        logger.error("‚ùå ALGUNOS TESTS FALLARON")
        logger.error(f"   {total - passed} test(s) con errores")
        logger.error("")
        return 1


if __name__ == "__main__":
    sys.exit(main())

