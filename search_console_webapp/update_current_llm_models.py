#!/usr/bin/env python3
"""
Script para actualizar los modelos LLM actuales en la base de datos.

Este script marca los modelos mÃ¡s recientes como 'is_current = TRUE'
para que el sistema de LLM Monitoring los use.

IMPORTANTE: Ejecutar este script en producciÃ³n para que los anÃ¡lisis
usen los modelos correctos (GPT-5, Gemini 3, Claude Sonnet 4.5, Sonar).

Uso:
    python update_current_llm_models.py
"""

import os
import sys

# AÃ±adir el directorio padre al path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from database import get_db_connection


def update_current_models():
    """
    Actualiza los modelos actuales en la BD.
    
    Modelos a configurar como actuales:
    - OpenAI: gpt-4o (GPT-5 no estÃ¡ disponible aÃºn en la API real)
    - Google: gemini-2.0-flash (Gemini 3 no estÃ¡ disponible aÃºn)  
    - Anthropic: claude-sonnet-4-5-20241022 (Claude Sonnet 4.5)
    - Perplexity: sonar
    
    NOTA: Actualiza estos valores cuando los modelos realmente estÃ©n disponibles.
    """
    
    conn = get_db_connection()
    if not conn:
        print("âŒ Error: No se pudo conectar a la base de datos")
        return False
    
    try:
        cur = conn.cursor()
        
        # Primero, mostrar estado actual
        print("\nðŸ“Š Estado ACTUAL de modelos en BD:")
        print("=" * 60)
        cur.execute("""
            SELECT llm_provider, model_id, model_display_name, is_current, is_available
            FROM llm_model_registry
            ORDER BY llm_provider, is_current DESC
        """)
        rows = cur.fetchall()
        
        current_models = {}
        for row in rows:
            status = "âœ… CURRENT" if row['is_current'] else "  "
            avail = "ðŸŸ¢" if row['is_available'] else "ðŸ”´"
            print(f"  {avail} {status} {row['llm_provider']:12} | {row['model_id']:30} | {row['model_display_name']}")
            if row['is_current']:
                current_models[row['llm_provider']] = row['model_id']
        
        print("\n" + "=" * 60)
        print("ðŸ“Œ Modelos ACTUALES por proveedor:")
        for provider, model in current_models.items():
            print(f"   {provider}: {model}")
        
        # Definir los modelos que DEBERÃAN ser actuales
        # IMPORTANTE: Usar modelos que REALMENTE existen en las APIs
        desired_models = {
            'openai': 'gpt-4o',  # GPT-4o es el mÃ¡s reciente disponible
            'google': 'gemini-2.0-flash',  # Gemini 2.0 Flash es el actual
            'anthropic': 'claude-sonnet-4-5-20241022',  # Claude Sonnet 4.5
            'perplexity': 'sonar'  # Sonar es correcto
        }
        
        print("\n" + "=" * 60)
        print("ðŸŽ¯ Modelos DESEADOS (mÃ¡s recientes disponibles):")
        for provider, model in desired_models.items():
            print(f"   {provider}: {model}")
        
        # Preguntar confirmaciÃ³n
        print("\n" + "=" * 60)
        response = input("Â¿Deseas actualizar los modelos actuales? (y/n): ").strip().lower()
        
        if response != 'y':
            print("âŒ OperaciÃ³n cancelada")
            return False
        
        # Actualizar cada proveedor
        print("\nðŸ”„ Actualizando modelos...")
        
        for provider, new_model in desired_models.items():
            # 1. Primero, quitar is_current de todos los modelos del proveedor
            cur.execute("""
                UPDATE llm_model_registry
                SET is_current = FALSE
                WHERE llm_provider = %s
            """, (provider,))
            
            # 2. Marcar el nuevo modelo como current
            cur.execute("""
                UPDATE llm_model_registry
                SET is_current = TRUE, is_available = TRUE
                WHERE llm_provider = %s AND model_id = %s
            """, (provider, new_model))
            
            if cur.rowcount > 0:
                print(f"   âœ… {provider}: {new_model} marcado como actual")
            else:
                # El modelo no existe, insertarlo
                print(f"   âš ï¸ {provider}: {new_model} no existe en BD, insertando...")
                
                # Pricing por defecto (ajustar segÃºn documentaciÃ³n oficial)
                default_pricing = {
                    'openai': {'input': 2.50, 'output': 10.00},
                    'google': {'input': 0.075, 'output': 0.30},
                    'anthropic': {'input': 3.00, 'output': 15.00},
                    'perplexity': {'input': 1.00, 'output': 1.00}
                }
                
                pricing = default_pricing.get(provider, {'input': 1.0, 'output': 1.0})
                
                cur.execute("""
                    INSERT INTO llm_model_registry 
                    (llm_provider, model_id, model_display_name, input_price_per_1m, output_price_per_1m, is_current, is_available)
                    VALUES (%s, %s, %s, %s, %s, TRUE, TRUE)
                """, (provider, new_model, new_model.upper(), pricing['input'], pricing['output']))
                
                print(f"   âœ… {provider}: {new_model} insertado y marcado como actual")
        
        conn.commit()
        
        # Mostrar estado final
        print("\n" + "=" * 60)
        print("ðŸ“Š Estado FINAL de modelos actuales:")
        cur.execute("""
            SELECT llm_provider, model_id, model_display_name
            FROM llm_model_registry
            WHERE is_current = TRUE
            ORDER BY llm_provider
        """)
        final_rows = cur.fetchall()
        
        for row in final_rows:
            print(f"   âœ… {row['llm_provider']:12} | {row['model_id']:30} | {row['model_display_name']}")
        
        print("\nâœ… Â¡Modelos actualizados correctamente!")
        print("â„¹ï¸  Los prÃ³ximos anÃ¡lisis usarÃ¡n estos modelos.")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        conn.rollback()
        return False
    finally:
        cur.close()
        conn.close()


def check_available_models():
    """
    Verifica quÃ© modelos estÃ¡n realmente disponibles en cada API.
    """
    print("\nðŸ” Verificando disponibilidad real de modelos...")
    print("=" * 60)
    
    # OpenAI
    try:
        import openai
        client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        models = client.models.list()
        gpt_models = [m.id for m in models.data if 'gpt' in m.id.lower()]
        print(f"\nðŸ“¦ OpenAI - Modelos GPT disponibles:")
        for m in sorted(gpt_models)[:10]:
            print(f"   â€¢ {m}")
    except Exception as e:
        print(f"   âš ï¸ OpenAI: {e}")
    
    # Google
    try:
        import google.generativeai as genai
        genai.configure(api_key=os.getenv('GOOGLE_AI_API_KEY'))
        models = genai.list_models()
        print(f"\nðŸ“¦ Google - Modelos Gemini disponibles:")
        for m in models:
            if 'gemini' in m.name.lower():
                print(f"   â€¢ {m.name}")
    except Exception as e:
        print(f"   âš ï¸ Google: {e}")
    
    print("\n" + "=" * 60)


if __name__ == '__main__':
    print("=" * 60)
    print("ðŸ¤– Actualizador de Modelos LLM - LLM Monitoring")
    print("=" * 60)
    
    # OpciÃ³n para verificar modelos disponibles
    if len(sys.argv) > 1 and sys.argv[1] == '--check':
        check_available_models()
    else:
        update_current_models()

