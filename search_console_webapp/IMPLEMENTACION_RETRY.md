# üîß Gu√≠a de Implementaci√≥n del Sistema de Retry

## üì¶ Archivos Creados

1. **`services/llm_providers/retry_handler.py`** - Sistema de retry inteligente
2. **`ANALISIS_RETRY_SYSTEM.md`** - An√°lisis completo del problema y soluci√≥n

---

## üöÄ C√≥mo Aplicar a Cada Provider

### **Ejemplo: OpenAI Provider**

#### **Antes (Sin Retry):**

```python
def execute_query(self, query: str) -> Dict:
    start_time = time.time()
    
    try:
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": query}],
            max_tokens=2000
        )
        # ... procesar respuesta ...
    except openai.RateLimitError as e:
        logger.error(f"‚ùå OpenAI Rate Limit: {e}")
        return {'success': False, 'error': "Rate limit exceeded"}
```

#### **Despu√©s (Con Retry):**

```python
from .retry_handler import with_retry

@with_retry  # ‚ú® Agregar decorator
def execute_query(self, query: str) -> Dict:
    start_time = time.time()
    
    try:
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": query}],
            max_tokens=2000
        )
        # ... procesar respuesta ...
    except openai.RateLimitError as e:
        logger.error(f"‚ùå OpenAI Rate Limit: {e}")
        # ‚ú® El decorator detectar√° "rate limit" y reintentar autom√°ticamente
        return {'success': False, 'error': "Rate limit exceeded"}
```

¬°Eso es TODO! El decorator hace el resto autom√°ticamente.

---

## üìù Pasos de Implementaci√≥n

### **Fase 1: OpenAI (Prioritario)**

```bash
# 1. Aplicar retry a OpenAI
# Editar: services/llm_providers/openai_provider.py

# L√≠nea 10: Agregar import
from .retry_handler import with_retry

# L√≠nea 75: Agregar decorator antes de execute_query
@with_retry
def execute_query(self, query: str) -> Dict:
    # ... c√≥digo existente sin cambios ...
```

### **Fase 2: Google, Anthropic, Perplexity**

Mismo proceso para cada uno:
1. Agregar import de `with_retry`
2. Agregar decorator `@with_retry` antes de `execute_query`
3. Sin cambios en el c√≥digo existente

### **Fase 3: Testing**

```python
# Test local con prompt que fall√≥:
python3 -c "
from services.llm_monitoring_service import MultiLLMMonitoringService

service = MultiLLMMonitoringService()

# Analizar proyecto HM Fertility
result = service.analyze_project(project_id=5, max_workers=10)

print('‚úÖ Resultado:', result)
"
```

### **Fase 4: Monitoreo**

```python
# Agregar endpoint para ver m√©tricas de retry
@app.route('/api/llm-monitoring/retry-metrics')
def get_retry_metrics():
    from services.llm_providers.retry_handler import retry_metrics
    return jsonify(retry_metrics.get_summary())
```

---

## üéØ Configuraci√≥n √ìptima por Provider

### **OpenAI (GPT-5)**
- **Max Retries**: 3 (rate limits frecuentes)
- **Timeout**: 60s (respuestas largas)
- **Priority**: ALTA (m√°s caro)

### **Google (Gemini)**
- **Max Retries**: 2 (muy estable)
- **Timeout**: 30s (muy r√°pido)
- **Priority**: BAJA (muy barato)

### **Anthropic (Claude Sonnet 4.5)**
- **Max Retries**: 3 (respuestas largas)
- **Timeout**: 90s (reasoning extenso)
- **Priority**: MEDIA

### **Perplexity (Sonar)**
- **Max Retries**: 2 (b√∫squeda en tiempo real puede tardar)
- **Timeout**: 45s
- **Priority**: MEDIA

---

## üìä Monitoreo Post-Implementaci√≥n

### **M√©tricas a Trackear (Primera Semana):**

```sql
-- Queries con retry exitoso
SELECT 
    llm_provider,
    COUNT(*) as total_retries,
    AVG(response_time_ms) as avg_time
FROM llm_monitoring_results
WHERE has_error = FALSE
AND created_at >= NOW() - INTERVAL '7 days'
-- Filtrar solo los que tuvieron retry (agregar campo retry_count)
GROUP BY llm_provider;

-- Tasa de fallos antes/despu√©s
SELECT 
    llm_provider,
    DATE(analysis_date) as date,
    COUNT(*) as total_queries,
    SUM(CASE WHEN has_error THEN 1 ELSE 0 END) as errors,
    ROUND(SUM(CASE WHEN has_error THEN 1 ELSE 0 END)::numeric / COUNT(*) * 100, 2) as error_rate
FROM llm_monitoring_results
WHERE analysis_date >= CURRENT_DATE - 14
GROUP BY llm_provider, DATE(analysis_date)
ORDER BY date DESC, llm_provider;
```

### **Alertas a Configurar:**

```python
# Si error rate > 5% despu√©s de retry
if error_rate > 0.05:
    send_alert("Provider X tiene alta tasa de fallos")

# Si promedio de reintentos > 1
if avg_retries > 1:
    send_alert("Provider X requiere muchos reintentos")

# Si un provider falla completamente
if provider_queries == 0:
    send_alert("Provider X no est√° respondiendo")
```

---

## üîß Troubleshooting

### **Problema: Demasiados Reintentos**

```
S√≠ntoma: An√°lisis tarda mucho tiempo
Soluci√≥n: Reducir max_retries o delay_initial
```

### **Problema: Sigue Fallando Despu√©s de Retry**

```
S√≠ntoma: Error rate sigue alto
Diagn√≥stico: 
1. Verificar tipo de error (¬øes retriable?)
2. ¬øAPI key v√°lida?
3. ¬øRate limits del proveedor?
4. ¬øProblema de red?
```

### **Problema: Costos Muy Altos**

```
S√≠ntoma: Costo API aument√≥ >20%
Soluci√≥n:
1. Reducir reintentos de providers caros (OpenAI)
2. Aumentar delay entre reintentos
3. Implementar circuit breaker
```

---

## ‚úÖ Checklist de Implementaci√≥n

- [ ] Revisar `retry_handler.py`
- [ ] Aplicar `@with_retry` a OpenAI
- [ ] Aplicar `@with_retry` a Google
- [ ] Aplicar `@with_retry` a Anthropic
- [ ] Aplicar `@with_retry` a Perplexity
- [ ] Testing local con proyecto de prueba
- [ ] Deploy a staging
- [ ] Monitorear m√©tricas 24h
- [ ] Ajustar configuraci√≥n si es necesario
- [ ] Deploy a producci√≥n
- [ ] Configurar alertas
- [ ] Documentar resultados

---

## üìà Resultados Esperados

### **Antes:**
- Error rate: 2-5%
- Datos incompletos: ~3% del tiempo
- Tickets de soporte por datos faltantes: 2-3/semana

### **Despu√©s (Estimado):**
- Error rate: 0.5-1%
- Datos incompletos: <0.5% del tiempo
- Tickets de soporte: <1/mes
- Costo adicional: $10-15/mes
- ROI: Positivo en primera semana

---

## üéì Buenas Pr√°cticas

1. **No reintentar errores permanentes** (API key inv√°lida, contenido bloqueado)
2. **Usar exponential backoff** (no sobrecargar APIs)
3. **Timeout apropiado** (60s general, ajustar por provider)
4. **Logging detallado** (para debugging)
5. **M√©tricas de rendimiento** (para optimizaci√≥n continua)

---

**Pr√≥ximo Review:** 1 semana despu√©s de implementaci√≥n  
**Responsable:** Equipo de Desarrollo  
**Priority:** Alta
